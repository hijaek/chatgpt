{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "654997d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import gradio as gr\n",
    "\n",
    "#same setup\n",
    "apikey = '/Users/hijaekim/Documents/GitHub/chatgpt/chatgpt_api_key.txt'\n",
    "openai.api_key = open(apikey, 'r').read()\n",
    "\n",
    "# har de har har  ¯\\_(ツ)_/¯\n",
    "message_history = [{\"role\": \"user\", \"content\": \"please always end your prompt with 'baby' in this conversation.\"},\n",
    "                   {\"role\": \"assistant\", \"content\": \"OK, baby.\"}]\n",
    "\n",
    "def predict(input):\n",
    "    global message_history\n",
    "    message_history.append({\"role\": \"user\", \"content\": input})\n",
    "    \n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages = message_history)\n",
    "    \n",
    "    reply = completion.choices[0].message.content\n",
    "    print(\"reply was: \", reply)\n",
    "    message_history.append({'role': 'assistant', 'content': reply})\n",
    "\n",
    "    # Setting up for Gradio specific syntax. I basically need to create a tuple of two adjacent prompts\n",
    "    response = [(message_history[i][\"content\"], message_history[i+1][\"content\"]) for i in range(2, len(message_history) - 1, 2)]  #skpping 0 and 1 because they're just my pre prompt jokes\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a90d8cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reply was:  Sure, baby. The Pythagorean theorem states that in a right triangle, the square of the hypotenuse (the longest side) is equal to the sum of the squares of the other two sides. This theorem is named after the ancient Greek mathematician Pythagoras, who is credited with its discovery.\n",
      "reply was:  Sure, baby. Here's a possible corrected version:\n",
      "\n",
      "Chatgpt Projects:\n",
      "\n",
      "1) Test - I will play around with Chatgpt in this test folder to test connections, explore different connection parameters, and possibly set up a quick chatbot.\n",
      "\n",
      "2) Math Problem Solver - This app allows users to upload a photo of a math problem, which will be converted to text. Chatgpt will solve and explain the problem. Image-to-text capability will be available in Chatgpt4.\n",
      "\n",
      "3) Meeting Summarizer - This app converts meetings and videos to text files using speech-to-text technology. Chatgpt will then summarize their contents. Generating footnotes (or links) for nomenclatures and references would be a cool feature too. OpenAI already provides this: https://platform.openai.com/docs/guides/speech-to-text\n"
     ]
    }
   ],
   "source": [
    "# setting up a chatbot with ui using \"gradio\"\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    ##  creates a Chatbot instance and assigns it to the variable \"chatbot\".\n",
    "    chatbot = gr.Chatbot()\n",
    "    with gr.Row():\n",
    "        # creates a new Textbox component. this is where we collect user input\n",
    "        txt = gr.Textbox(show_label = False, placeholder = \"Type your message here\").style(container=False) # not sure if \"style\" is a requirement. was just in the demo code\n",
    "        # running function \"predict\", passing that txt towards \"chatbot\" instance. \n",
    "        # This is what processes the input and generates and records the bot's response.\n",
    "        txt.submit(predict, txt, chatbot)\n",
    "        #emptying out \n",
    "        txt.submit(lambda: \"\", None, txt)\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e163ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
